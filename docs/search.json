[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Obesity Data Analysis",
    "section": "",
    "text": "1 Introduction\nObesity is an escalating global pandemic that has taken over many countries in the world. Overweight and obesity are the fifth leading risk for global deaths, and a leading preventable cause of death (only second to smoking in the US).\nWith more than 40% of Americans being obese, our team was outraged by the scale of this problem. Being obese not only has detrimental effects on a person’s health, it also drastically impacts their self-confidence and self-image. While great efforts have been made by body positivity activists to encourage people to embrace their appearances regardless of their size, it is undeniable that people who are overweight still face a great deal of prejudice and inconveniences in their daily lives that can be easily resolved, if only they were able to lose weight by leading a healthier lifestyle.\nIn order to tackle this problem, we seek to understand what health and physical factors are typically associated with obesity. This will be useful to the community in two ways:\n\nEmpower overweight individuals by allowing them to understand what factors might have contributed to or have been caused by their weight.\nIncrease general understanding of the problem of obesity such that the non-obese population is more empathetic towards obese individuals.\n\nIn this project, we use techniques learnt in the course “Exploratory Data Analysis and Visualization” by Professor Joyce Robbins at Columbia University to inspect our chosen dataset from many angles, describing and summarizing the dataset without making any precise assumptions about the data. Here is a quick overview of the other pages:\n\nData: Presentation of our dataset and research methodology\nResults: The exploratory techniques used on the dataset and our findings\nInteractive graph: Interactive parallel coordinates plot to visualize relationships between variables\nConclusion: Key findings of our exploration, limitations of our analyses and future directions."
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\n\n2.1.1 Overview of attributes\nWe are using one data source for this project, presented in the research paper Palechor et al. 2019, that monitors the physical health of individuals of ages 14 to 61 from the countries of Mexico, Peru and Colombia, based on their eating habits, physical condition and obesity levels. The dataset contains 17 attributes and 2111 records, and it is the biggest (in terms of both the number of rows and columns) dataset that we could find on obesity and physical health. The 17 attributes are as follows:\n\n\n\n\n\n\n\n\n\nIndex\nVariable\nType\nSubtype\n\n\n\n\n1\nGender\nCategorical\nNominal\n\n\n2\nAge\nNumerical\nDiscrete\n\n\n3\nHeight\nNumerical\nContinuous\n\n\n4\nWeight\nNumerical\nContinuous\n\n\n5\nFamily history with overweight (family_history_with_overweight)\nCategorical\nBinary\n\n\n6\nFrequent consumption of high caloric food (FAVC)\nCategorical\nBinary\n\n\n7\nFrequency of consumption of vegetables (FCVC)\nNumerical\nDiscrete\n\n\n8\nNumber of main meals (NCP)\nNumerical\nDiscrete\n\n\n9\nConsumption of food between meals (CAEC)\nCategorical\nOrdinal\n\n\n10\nSMOKE\nCategorical\nBinary\n\n\n11\nConsumption of water daily (CH2O)\nNumerical\nDiscrete\n\n\n12\nCalories consumption monitoring (SCC)\nCategorical\nBinary\n\n\n13\nPhysical activity frequency (FAF)\nNumerical\nDiscrete\n\n\n14\nTime using technology devices (TUE)\nNumerical\nDiscrete\n\n\n15\nConsumption of alcohol (CALC)\nCategorical\nOrdinal\n\n\n16\nTransportation used (MTRANS)\nCategorial\nNominal\n\n\n17\nObesity category level (NObeyesdad)\nCategorical\nOrdinal\n\n\n\n\n\n\n\n2.1.2 Dealing with class imbalance\n485 rows (or 23%) of this data was collected using an online survey that was made available online for a period of 30 days (exact dates not specified), and the researchers generated the remaining 77% synthetically in order to balance out the categories of obesity levels. It is understandable that the researchers had to generate synthetic data as the categories naturally will suffer from a huge imbalance favoring people of normal weight. Obesity levels are calculated based on the person’s Body Mass Index (BMI), given by the following formula \\(\\frac{weight}{height*height}\\). The categories of the obesity level are fixed by the World Health Organization, as follows:\n\n\n\nObesity level category\nBMI\n\n\n\n\nUnderweight\nLess than 18.5\n\n\nNormal\n18.5 to 24.9\n\n\nOverweight\n25.0 to 29.9\n\n\nObesity I\n30.0 to 34.9\n\n\nObesity II\n35.0 to 39.9\n\n\nObesity III\nHigher than 40\n\n\n\nA person’s BMI is normally distributed, which explains why there are many more instances of people in a healthy health range as compared to other obesity level categories. By synthesizing more data for minority categories, the researchers pre-empt the fact that class imbalances will cause learning problems in the data mining methods and also difficulties when doing exploratory data analysis on this dataset. The researchers used an advanced technique to generate this data, the Synthetic Minority Oversampling TEchnique (SMOTE) technique developed by Chawla et. al 2002 has shown to achieve superior results on classification tasks as compared to the typical method of simply oversampling minorities as it generates new synthetic minority data using the k-nearest neighbors machine learning algorithm. The SMOTE algorithm that was described in the paper can also be found in the Annex, Chapter 6 of this report.\n \nThese are the reasons why our team chose this obesity dataset in particular: it not only provides a large range of metrics associated with a person’s health that are generally correlated with obesity for us to analyze, but also addresses class imbalances in a reliable way.\nWe plan to import the data directly into RStudio using the readfile function.\n\n\n2.1.3 Dealing with duplicate rows\nThe dataset contains a few duplicate rows, which could be attributed to the SMOTE algorithm. We decided to keep most of these duplicates as they are present in a very small number (2) except for one which had 15 duplicates\n\n\n2.1.4 Need for new columns\nWe included a new 18th attribute, BMI, so as to be able to do a regression analysis as the BMI (numerical data) provides more information than the obesity category level (categorical data)."
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research plan",
    "text": "2.2 Research plan\nWe intend to explore the health factors that are the most correlated with a person’s BMI or obesity level and visualize them. In the 17 attributes of our dataset, there are 5 categorical binary variables, 4 multicategorical variables and 8 continuous variables. We intend on using the techniques seen in class, such as scatter plots and boxplots, to explore this dataset.\nFrom these correlations, we will be able to draw some conclusions about the people who are the most at risk of becoming obese."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\n\n2.3.1 No missing values in the dataset\nThe data has been preprocessed by Palechor et al. prior to applying the SMOTE filter, as missing/anomalous data will propagate errors in the synthetic data. The researchers mentioned identifying atypical and missing data in their paper, but they unfortunately did not specify exactly how much data was missing or anomalous, neither did they mention how did they remedy the problem (e.g. using correlations between the different columns of the datasets). It is also unfortunate that the researchers did not clearly indicate which rows of the dataset were synthetically generated, and which rows were collected from the online survey, neither did they make the original raw dataset open source. Nevertheless, we appreciate the robustness and completeness of this dataset.\n\n\nCode\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(reshape2)\ndata&lt;-read_csv(\"materials/ObesityDataSet_raw_and_data_sinthetic.csv\",show_col_types = FALSE)\n\nmissing_values &lt;- is.na(data)\n\n# Reshape data for heatmap\nlong_data &lt;- melt(missing_values, varnames = c(\"Variable\", \"Observation\"))\n\n# Create the heatmap\nggplot(long_data, aes(x = Variable, y = Observation, fill = value)) +\n  geom_tile() +\n  scale_fill_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"lightgreen\"), name = \"Missing\", labels = c(\"No\", \"Yes\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.title = element_blank())\n\n\n\n\n\n\n\n\n2.3.2 Potential methods to handle missing values\nIf our dataset were to have missing values, we would have dealt with it using one of the following methods: 1. Use plot_missing() from redav to plot the number of missing values in each column and see the missing patterns along with their counts. 2. If there are missing patterns with correlations between the missing columns, we can see if it is possible to use the value of any of the other columns as a good predictor of the value of the column(s) with missing values, for example by doing a linear regression. 3. If the proportion of NA values is low, we can also simply try removing NA values from only these columns and keep all the other data."
  },
  {
    "objectID": "d3graph.html",
    "href": "d3graph.html",
    "title": "4  Interactive graph",
    "section": "",
    "text": "Age  Height  Weight  FCVC  NCP  FAF  TUE  BMI Update"
  },
  {
    "objectID": "results.html#data-pre-processing",
    "href": "results.html#data-pre-processing",
    "title": "3  Results",
    "section": "3.2 Data pre-processing",
    "text": "3.2 Data pre-processing\nTo conduct deeper analysis on our data, we added the following columns to our dataset:\n\nBMI: the Body Mass Index of each person, a continuous variable calculated using the World Health Organization guideline: \\(BMI = \\frac{Weight}{Height^2}\\).\nIsOverweight: a binary categorical value whose value is 1 if the BMI of the person is more than 25, 0 otherwise.\n\nThese columns serve as alternate metrics of the obesity of an individual, a continuous variable and a binary categorical variable, to complement NObeyesdad, the obesity category level which is a ordinal categorical variable.\nThese new columns can be found and used directly in the dataset scripts/xinyi-zhao_files/CleanObesityDataSet.csv.\nIn order to improve the visualization of certain plots, we also made local modifications to the data types of some columns, as follows:\n\nRounded the variables: Frequency of consumption of vegetables (FCVC), Number of main meals (NCP), Physical activity frequency (FAF), Time using technology devices (TUE)"
  },
  {
    "objectID": "results.html#verifications-of-the-validity-of-the-dataset",
    "href": "results.html#verifications-of-the-validity-of-the-dataset",
    "title": "3  Results",
    "section": "3.2 Verifications of the validity of the dataset",
    "text": "3.2 Verifications of the validity of the dataset\nWe start by importing the necessary libraries and the clean dataset.\n\n\nCode\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(stats)\nlibrary(vcd)\nlibrary(ggplot2)\nlibrary(gridExtra)\n\ndata &lt;- read_csv('materials/CleanObesityDataSet.csv',show_col_types = FALSE)\n\n\nWe then do some preliminary verifications of the dataset:\n\n\nCode\ncat(\"Number of rows in dataset: \", nrow(data), \"\\nNumber of columns in dataset: \", ncol(data),\"\\nNumber of missing values in dataset: \", sum(is.na(data)))\n\n\nNumber of rows in dataset:  2111 \nNumber of columns in dataset:  20 \nNumber of missing values in dataset:  0\n\n\nAt first glance there does not seem to be any problems with the structure of our dataset, so we proceed with verifying that the data seems to align with our expectations, that there are no biases with respect to the people surveyed. We do this by visualizing the Height, Weight and BMI variables using a histogram:\n\n\nCode\n# Histograms of Height, Weight and BMI\nplot1 &lt;- ggplot(data = data, aes(x = Height)) + geom_histogram(binwidth = 0.02)\nplot2 &lt;- ggplot(data = data, aes(x = Weight)) + geom_histogram(binwidth = 2)\nplot3 &lt;- ggplot(data = data, aes(x = BMI)) + geom_histogram(binwidth = 1)\ngrid.arrange(plot1, plot2, plot3, ncol = 3)\n\n\n\n\n\n\n\nCode\n# Boxplot to visualize the BMI across all individuals \nggplot(data, aes(x=BMI)) + \n  geom_boxplot(fill = \"lightblue\", color = \"black\") + \n  coord_cartesian(ylim = c(-2, 2)) +  \n  labs(title = \"Boxplot of BMI across all individuals\")"
  },
  {
    "objectID": "results.html#understanding-the-correlation-between-biological-factor-and-obesity",
    "href": "results.html#understanding-the-correlation-between-biological-factor-and-obesity",
    "title": "3  Results",
    "section": "3.5 Understanding the correlation between biological factor and obesity",
    "text": "3.5 Understanding the correlation between biological factor and obesity"
  },
  {
    "objectID": "results.html#correlation-between-lifestyle-habits-and-obesity",
    "href": "results.html#correlation-between-lifestyle-habits-and-obesity",
    "title": "3  Results",
    "section": "3.6 Correlation between lifestyle habits and obesity",
    "text": "3.6 Correlation between lifestyle habits and obesity\n\n\n\nCode\n# Creating individual density plots with smooth lines\nplot_fcvc &lt;- ggplot(data, aes(x = FCVC)) + \n  stat_density(aes(y = ..density..), geom = \"area\", fill=\"blue\", alpha=0.5) +\n  ggtitle(\"FCVC Density Plot\") +\n  xlab(\"FCVC\") +\n  ylab(\"Density\")\n\nplot_ncp &lt;- ggplot(data, aes(x = NCP)) + \n  stat_density(aes(y = ..density..), geom = \"area\", fill=\"blue\", alpha=0.5) +\n  ggtitle(\"NCP Density Plot\") +\n  xlab(\"NCP\") +\n  ylab(\"Density\")\n\nplot_faf &lt;- ggplot(data, aes(x = FAF)) + \n  stat_density(aes(y = ..density..), geom = \"area\", fill=\"blue\", alpha=0.5) +\n  ggtitle(\"FAF Density Plot\") +\n  xlab(\"FAF\") +\n  ylab(\"Density\")\n\nplot_tue &lt;- ggplot(data, aes(x = TUE)) + \n  stat_density(aes(y = ..density..), geom = \"area\", fill=\"blue\", alpha=0.5) +ggtitle(\"TUE Density Plot\") +\n  xlab(\"TUE\") +\n  ylab(\"Density\")\n\n# Arrange the plots in a 2x2 grid\ngrid.arrange(plot_fcvc, plot_ncp, plot_faf, plot_tue, nrow = 2)\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\nCode\ncategories &lt;- c('Insufficient_Weight','Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II', 'Obesity_Type_I', 'Obesity_Type_II','Obesity_Type_III')\n\n# Create a mapping from category to integer\ncategory_mapping &lt;- setNames(1:length(categories), categories)\n\ndata$NObesity_numeric &lt;- as.integer(factor(data$NObeyesdad, levels = categories))\n\ndata_pca &lt;- data[c(\"FCVC\",\"NCP\",\"FAF\",\"TUE\",\"NObesity_numeric\")]\n\n\ncor_matrix &lt;- cor(data_pca)\n\n# Reshape the data for heatmap\nmelted_cor &lt;- melt(cor_matrix)\n\n# Creating heatmap\nggplot(melted_cor, aes(Var1, Var2, fill = value)) +\n  geom_tile() +\n  geom_text(aes(label = ifelse(value &gt; 0.1&value&lt;1, round(value, 2), '')), color= 'darkblue',vjust = 1) +\n  scale_fill_gradient2(midpoint = 0) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  ggtitle(\"Heatmap of Correlations\")"
  },
  {
    "objectID": "results.html#verify-the-validity-of-the-dataset",
    "href": "results.html#verify-the-validity-of-the-dataset",
    "title": "3  Results",
    "section": "3.2 Verify the validity of the dataset",
    "text": "3.2 Verify the validity of the dataset\nWe start by importing the necessary libraries and the clean dataset.\n\n\nCode\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(stats)\nlibrary(vcd)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\n\ndata &lt;- read_csv('materials/CleanObesityDataSet.csv',show_col_types = FALSE)\n\n\nWe then do some preliminary verifications of the number of rows, columns and missing values of our dataset:\n\n\nCode\ncat(\"Number of rows in dataset: \", nrow(data), \"\\nNumber of columns in dataset: \", ncol(data),\"\\nNumber of missing values in dataset: \", sum(is.na(data)))\n\n\nNumber of rows in dataset:  2111 \nNumber of columns in dataset:  20 \nNumber of missing values in dataset:  0\n\n\nAt first glance there does not seem to be any problems with the structure of our dataset, so we proceed with verifying that the data seems to align with our expectations, that there are no biases with respect to the people surveyed. We do this by visualizing the Height, Weight and BMI variables using a histogram:\n\n\nCode\n# Histograms of Height, Weight and BMI\nplot1 &lt;- ggplot(data = data, aes(x = Height)) + geom_histogram(binwidth = 0.02)\nplot2 &lt;- ggplot(data = data, aes(x = Weight)) + geom_histogram(binwidth = 2)\nplot3 &lt;- ggplot(data = data, aes(x = BMI)) + geom_histogram(binwidth = 1)\ngrid.arrange(plot1, plot2, plot3, ncol = 3,\n     top = textGrob(\"Histograms of continuous variables Height, Weight and BMI\",gp=gpar(fontsize=16)))\n\n\n\n\n\n\n\nCode\n# Boxplot to visualize the BMI across all individuals \nggplot(data, aes(x=BMI)) + \n  geom_boxplot(fill = \"lightblue\", color = \"black\") + \n  coord_cartesian(ylim = c(-2, 2)) +  \n  labs(title = \"Boxplot of BMI across all individuals\")"
  },
  {
    "objectID": "results.html#summary-of-findings",
    "href": "results.html#summary-of-findings",
    "title": "3  Results",
    "section": "3.1 Summary of findings",
    "text": "3.1 Summary of findings\nIn the next few subsections, we dive into the details of how we drew these conclusions."
  },
  {
    "objectID": "results.html#verifications-that-the-dataset-is-valid",
    "href": "results.html#verifications-that-the-dataset-is-valid",
    "title": "3  Results",
    "section": "3.3 Verifications that the dataset is valid",
    "text": "3.3 Verifications that the dataset is valid\nImporting the necessary libraries and dataset\n\n\nCode\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(stats)\nlibrary(vcd)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\n\ndata &lt;- read_csv('materials/CleanObesityDataSet.csv',show_col_types = FALSE)\n\n\nPreliminary verifications of the number of rows, columns and missing values of our dataset show that there does not seem to be any problems with the structure of our dataset.\n\n\nCode\ncat(\"Number of rows in dataset: \", nrow(data), \"\\nNumber of columns in dataset: \", ncol(data),\"\\nNumber of missing values in dataset: \", sum(is.na(data)))\n\n\nNumber of rows in dataset:  2111 \nNumber of columns in dataset:  20 \nNumber of missing values in dataset:  0\n\n\nAdditionally, the data seems to align with our expectations, visualizing the Height, Weight and BMI variables shows that there are no biases with respect to the people surveyed.\n\n\nCode\n# Histograms of Height, Weight and BMI\nplot1 &lt;- ggplot(data = data, aes(x = Height)) + geom_histogram(binwidth = 0.02)\nplot2 &lt;- ggplot(data = data, aes(x = Weight)) + geom_histogram(binwidth = 2)\nplot3 &lt;- ggplot(data = data, aes(x = BMI)) + geom_histogram(binwidth = 1)\ngrid.arrange(plot1, plot2, plot3, ncol = 3,\n     top = textGrob(\"Histograms of the continuous variables Height, Weight and BMI\",gp=gpar(fontsize=16)))\n\n\n\n\n\n\n\nCode\nshapiro.test(data$Height)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  data$Height\nW = 0.99323, p-value = 2.772e-08\n\n\nCode\nshapiro.test(data$Weight)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  data$Weight\nW = 0.9765, p-value &lt; 2.2e-16\n\n\nCode\nshapiro.test(data$BMI)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  data$BMI\nW = 0.97475, p-value &lt; 2.2e-16\n\n\n\n\nCode\nplot1 &lt;- ggplot(data, aes(sample = Height)) + \n  stat_qq() + \n  stat_qq_line(col = \"navy\") +\n  xlab(\"Height\")\n\nplot2 &lt;- ggplot(data, aes(sample = Weight)) + \n  stat_qq() + \n  stat_qq_line(col = \"navy\") +\n  xlab(\"Weight\")\n\nplot3 &lt;- ggplot(data, aes(sample = BMI)) + \n  stat_qq() + \n  stat_qq_line(col = \"navy\") +\n  xlab(\"BMI\")\n\ngrid.arrange(plot1, plot2, plot3, ncol = 3)\n\n\n\n\n\nAnalysis:\n\nThe height of the individuals appears to follow a normal distribution, which is aligned with our expectations as it is an assumption that researchers typically make.\nThe weight of the individuals does not appear to be normally distribution as it has a right skew. Body weight is found to have a right skew according to research.\nThe BMI of individuals\n\nWe confirmed the above results by visualizing the QQ plots of the three variables:\n\n\nCode\n# Boxplot to visualize the BMI across all individuals \nggplot(data, aes(x=BMI)) + \n  geom_boxplot(fill = \"lightblue\", color = \"black\") + \n  coord_cartesian(ylim = c(-2, 2)) +  \n  labs(title = \"Boxplot of BMI across all individuals\")"
  },
  {
    "objectID": "results.html#analysis-of-height-weight-and-bmi-variables",
    "href": "results.html#analysis-of-height-weight-and-bmi-variables",
    "title": "3  Results",
    "section": "3.3 Analysis of Height, Weight and BMI variables",
    "text": "3.3 Analysis of Height, Weight and BMI variables\nSince the dataset contains artificially generated data, we first needed to verify that the dataset matches our expectations, notably by visualizing the distribution of these three continuous variables.\nImporting the necessary libraries and dataset\n\n\nCode\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(stats)\nlibrary(vcd)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(GGally)\nlibrary(reshape2)\n\ndata &lt;- read_csv('scripts/xinyi-zhao_files/CleanObesityDataSet.csv',show_col_types = FALSE)\n\n\nPreliminary verifications of the number of rows, columns and missing values of our dataset show that there does not seem to be any problems with the structure of our dataset.\n\n\nCode\ncat(\"Number of rows in dataset: \", nrow(data), \"\\nNumber of columns in dataset: \", ncol(data),\"\\nNumber of missing values in dataset: \", sum(is.na(data)))\n\n\nNumber of rows in dataset:  2111 \nNumber of columns in dataset:  20 \nNumber of missing values in dataset:  0\n\n\nAdditionally, the data seems to align with our expectations, visualizing the Height, Weight and BMI variables shows that there are no biases with respect to the people surveyed.\n\n\nCode\n# Histograms of Height, Weight and BMI\nplot1 &lt;- ggplot(data = data, aes(x = Height)) + geom_histogram(binwidth = 0.02)\nplot2 &lt;- ggplot(data = data, aes(x = Weight)) + geom_histogram(binwidth = 2)\nplot3 &lt;- ggplot(data = data, aes(x = BMI)) + geom_histogram(binwidth = 1)\ngrid.arrange(plot1, plot2, plot3, ncol = 3,\n     top = textGrob(\"Histograms of the continuous variables Height, Weight and BMI\",gp=gpar(fontsize=16)))\n\n\n\n\n\n\n\nCode\nshapiro.test(data$Height)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  data$Height\nW = 0.99323, p-value = 2.772e-08\n\n\nCode\nshapiro.test(data$Weight)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  data$Weight\nW = 0.9765, p-value &lt; 2.2e-16\n\n\nCode\nshapiro.test(data$BMI)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  data$BMI\nW = 0.97475, p-value &lt; 2.2e-16\n\n\n\n\nCode\nplot1 &lt;- ggplot(data, aes(sample = Height)) + \n  stat_qq() + \n  stat_qq_line(col = \"navy\") +\n  xlab(\"Height\")\n\nplot2 &lt;- ggplot(data, aes(sample = Weight)) + \n  stat_qq() + \n  stat_qq_line(col = \"navy\") +\n  xlab(\"Weight\")\n\nplot3 &lt;- ggplot(data, aes(sample = BMI)) + \n  stat_qq() + \n  stat_qq_line(col = \"navy\") +\n  xlab(\"BMI\")\n\ngrid.arrange(plot1, plot2, plot3, ncol = 3)\n\n\n\n\n\nAnalysis:\nOn the histogram, it is not possible to tell for all three continuous variables whether they follow a normal\n\nThe height of the individuals appears to follow a normal distribution, which is aligned with our expectations as it is an assumption that researchers typically make.\nThe weight of the individuals does not appear to be normally distribution as it has a right skew. Body weight is found to have a right skew according to research.\nThe BMI of individuals\n\nLastly, we plotted a boxplot to better understand the other statistics (e.g. median, outliers) of the variable BMI.\n\n\nCode\n# Boxplot to visualize the BMI across all individuals \nggplot(data, aes(x=BMI)) + \n  geom_boxplot(fill = \"lightblue\", color = \"black\") + \n  coord_cartesian(ylim = c(-2, 2)) +  \n  labs(title = \"Boxplot of BMI across all individuals\")\n\n\n\n\n\nCode\nfivenum(data$BMI)\n\n\n[1] 12.99868 24.32580 28.71909 36.01650 50.81175"
  },
  {
    "objectID": "results.html#preliminary-visualizations",
    "href": "results.html#preliminary-visualizations",
    "title": "3  Results",
    "section": "3.4 Preliminary visualizations",
    "text": "3.4 Preliminary visualizations\n\n\nCode\ndata_num &lt;- data[c(\"Age\", \"Height\", \"Weight\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\",\"BMI\")]\n\n# Convert all columns to numeric\ndata_num &lt;- sapply(data_num, as.numeric)\n\ndata &lt;- data %&gt;%\n mutate_if(is.numeric, scale)\n\nlibrary(GGally)\np &lt;- ggpairs(as.data.frame(data_num), aes(alpha = 0.2, size = 1))\n\np"
  }
]